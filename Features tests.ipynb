{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import features as cf\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_extractors():\n",
    "    # Extraigo dos atributos simples: \n",
    "    # 1) Longitud del mail.\n",
    "    # 2) Cantidad de espacios en el mail.\n",
    "    # 3) Tiene el mail contenido HTML?\n",
    "    # 4) Tiene el mail im√°genes?\n",
    "    # 5) Cantidad de oraciones\n",
    "    \n",
    "    return [ ('body_length', cf.body_length), \n",
    "      ('count_spaces', cf.count_spaces), \n",
    "      ('has_html', cf.has_html), \n",
    "      ('has_image', cf.has_image), \n",
    "      ('number_of_sentences', cf.number_of_sentences) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorizer_extractor(vectorizer_type, **kwargs):\n",
    "    if vectorizer_type == \"bow\":\n",
    "        vectorizer = CountVectorizer(stop_words='english', **kwargs)\n",
    "    elif vectorizer_type == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', **kwargs)\n",
    "    elif vectorizer_type == \"hashing_bow\":\n",
    "        vectorizer = HashingVectorizer(stop_words='english', **kwargs)\n",
    "    else:\n",
    "        raise ValueError('Invalid vectorizer_type. Expected \\'bow\\', \\'tfidf\\' or \\'hashing_bow\\'')\n",
    "    \n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_extractors(simple_features=True, subject_vectorizer='tfidf', body_vectorizer='tfidf', body_and_subject_vectorizer=None):\n",
    "    extractors = []\n",
    "    if simple_features:\n",
    "        # Simple features extactor\n",
    "        extractors = [('simple_features', cf.SimpleFeaturesExtractor(simple_extractors()))]\n",
    "    \n",
    "    if body_and_subject_vectorizer is not None:\n",
    "        # Pipeline for pulling vectorizer features from the post's body\n",
    "        extractors = extractors + \\\n",
    "            [('body_and_subject', Pipeline([\n",
    "                ('selector', ColumnSelectorExtractor('body_and_subject')),\n",
    "                (body_vectorizer, vectorizer_extractor(body_and_subject_vectorizer)),\n",
    "            ]))]\n",
    "    else:\n",
    "        if subject_vectorizer is not None:\n",
    "            # Pipeline for pulling vectorizer features from the post's subject\n",
    "            extractors = extractors + \\\n",
    "                [('subject', Pipeline([\n",
    "                    ('selector', ColumnSelectorExtractor('subject')),\n",
    "                    (subject_vectorizer, vectorizer_extractor(subject_vectorizer)),\n",
    "                ]))]\n",
    "\n",
    "        if body_vectorizer is not None:\n",
    "            # Pipeline for pulling vectorizer features from the post's body\n",
    "            extractors = extractors + \\\n",
    "                [('body', Pipeline([\n",
    "                    ('selector', ColumnSelectorExtractor('body')),\n",
    "                    (body_vectorizer, vectorizer_extractor(body_vectorizer)),\n",
    "                ]))]\n",
    "    \n",
    "    # Use FeatureUnion to combine the features\n",
    "    return FeatureUnion(extractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataset/ham_dev.json\n",
      "Done in 3.470076s\n",
      "Loaded 45000(465.272MB) mails\n",
      "Parsing mails\n",
      "Done in 17.655162s\n",
      "Parsed 45000 mails\n",
      "Loading data from dataset/spam_dev.json\n",
      "Done in 1.959641s\n",
      "Loaded 45000(200.517MB) mails\n",
      "Parsing mails\n",
      "Done in 17.517740s\n",
      "Parsed 45000 mails\n",
      "Generating Pandas DataFrame\n",
      "Done in 60.748598s\n",
      "Splitting into Training and Test Set\n",
      "Done in 60.817210s\n",
      "Train Set: 72000 samples - Ham: 35925(0.50%) Spam: 36075(0.50%)\n",
      "Test Set:  18000 samples - Ham: 9075(0.50%) Spam: 8925(0.50%)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = load_data(merge_body_and_subject=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('S32') dtype('S32') dtype('S32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e570adab845a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_pipeline_unified_body_and_subject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Mean : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" STD: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('S32') dtype('S32') dtype('S32')"
     ]
    }
   ],
   "source": [
    "dt_pipeline_unified_body_and_subject = Pipeline([\n",
    "  ('features_extractor', features_extractors(True, body_and_subject_vectorizer='tfidf')),\n",
    "  ('tree_classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "result = cross_val_score(dt_pipeline_unified_body_and_subject, train_set, train_set['label'], cv=10, n_jobs=-1)\n",
    "print \"Mean : \" + np.asarray(result).mean() + \" STD: \" + np.asarray(result).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_pipeline_splitted_body_and_subject = Pipeline([\n",
    "  ('features_extractor', features_extractors(True, 'tfidf', 'tfidf')),\n",
    "  ('tree_classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "result = cross_val_score(dt_pipeline_splitted_body_and_subject, train_set, train_set['label'], cv=10, n_jobs=-1)\n",
    "print \"Mean : \" + np.asarray(result).mean() + \" STD: \" + np.asarray(result).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
