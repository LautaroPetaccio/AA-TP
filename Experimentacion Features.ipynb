{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es decidir que extractores de features usamos en el pipeline principal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Development\\Anaconda2\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import features as cf\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos definir los siguientes extractores de features:\n",
    "1. Features sencillos, definidos en features.py, como por ejemplo longitud del cuerpo del mail, o si contiene imagenes\n",
    "2. Vectorización (ya sea por medio del método Bag Of Words, del método TF-IDF, o del método Hashing Vectorizer) del Subject\n",
    "3. Vectorización (idem anterior) del Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vectorizer_extractor(vectorizer_type='bow', **kwargs):\n",
    "    if vectorizer_type == \"bow\":\n",
    "        vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2), **kwargs)\n",
    "    elif vectorizer_type == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), **kwargs)\n",
    "    elif vectorizer_type == \"hashing_bow\":\n",
    "        vectorizer = HashingVectorizer(stop_words='english', ngram_range=(1, 2), **kwargs)\n",
    "    else:\n",
    "        raise ValueError('Invalid vectorizer_type. Expected \\'bow\\', \\'tfidf\\' or \\'hashing_bow\\'')\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "def column_extractor(column_name, vectorizer_type='bow', **vect_kwargs):\n",
    "    if not vectorizer_type is None:\n",
    "        return Pipeline([\n",
    "            ('selector', ColumnSelectorExtractor(column_name)),\n",
    "            (vectorizer_type, vectorizer_extractor(vectorizer_type, **vect_kwargs))])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def subject_and_body_merged_extractor(vectorizer_type='bow', **vect_kwargs):\n",
    "    if not vectorizer_type is None:\n",
    "        return Pipeline([\n",
    "            ('selector', SubjectAndBodyMergerExtractor()),\n",
    "            (vectorizer_type, vectorizer_extractor(vectorizer_type, **vect_kwargs))])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def splitted_features_extractors(simple_features=True,\n",
    "                        subject_vectorizer='bow',\n",
    "                        body_vectorizer='bow',\n",
    "                        **vect_kwargs):\n",
    "    if simple_features:\n",
    "        # Some simple handmade features\n",
    "        simple_extractors = [ ('body_length', cf.body_length),\n",
    "                             ('count_spaces', cf.count_spaces),\n",
    "                             ('has_html', cf.has_html), \n",
    "                             ('has_image', cf.has_image), \n",
    "                             ('number_of_sentences', cf.number_of_sentences) ]\n",
    "        \n",
    "        extractors = [('simple', cf.SimpleFeaturesExtractor(simple_extractors))]\n",
    "        features_name = 'simple_'\n",
    "    else:\n",
    "        extractors = []\n",
    "        features_name = ''\n",
    "        \n",
    "    if subject_vectorizer is not None:\n",
    "        extractors = extractors + [('subject', column_extractor('subject',\n",
    "                                           vectorizer_type=subject_vectorizer,\n",
    "                                           **vect_kwargs))]        \n",
    "        features_name = features_name + 'subject_' + subject_vectorizer + '_'\n",
    "\n",
    "    if body_vectorizer is not None:\n",
    "        extractors = extractors + [('body', column_extractor('body',\n",
    "                                        vectorizer_type=body_vectorizer,\n",
    "                                        **vect_kwargs))]\n",
    "        features_name = features_name + 'body_' + body_vectorizer + '_'\n",
    "        \n",
    "    features_name = features_name[:-1]\n",
    "\n",
    "    if len(extractors) == 0:\n",
    "        return None\n",
    "    if len(extractors) == 1:\n",
    "        return extractors[0][1], features_name\n",
    "    else:\n",
    "        return FeatureUnion(extractors), features_name\n",
    "    \n",
    "def merged_features_extractors(simple_features=True,\n",
    "                        merged_vectorizer='bow',                        \n",
    "                        **vect_kwargs):\n",
    "    if simple_features:\n",
    "        # Some simple handmade features\n",
    "        simple_extractors = [ ('body_length', cf.body_length),\n",
    "                             ('count_spaces', cf.count_spaces),\n",
    "                             ('has_html', cf.has_html), \n",
    "                             ('has_image', cf.has_image), \n",
    "                             ('number_of_sentences', cf.number_of_sentences) ]\n",
    "        \n",
    "        extractors = [('simple', cf.SimpleFeaturesExtractor(simple_extractors))]\n",
    "        features_name = 'simple_'\n",
    "    else:\n",
    "        extractors = []\n",
    "        features_name = ''\n",
    "        \n",
    "    if merged_vectorizer is not None:\n",
    "        extractors = extractors + [('subject_and_body', subject_and_body_merged_extractor(\n",
    "                                           vectorizer_type=merged_vectorizer,\n",
    "                                           **vect_kwargs))]        \n",
    "        features_name = features_name + 'subject_and_body_' + merged_vectorizer + '_'\n",
    "\n",
    "    features_name = features_name[:-1]\n",
    "\n",
    "    if len(extractors) == 0:\n",
    "        return None\n",
    "    if len(extractors) == 1:\n",
    "        return extractors[0][1], features_name\n",
    "    else:\n",
    "        return FeatureUnion(extractors), features_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = joblib.load('dataset/train_set.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada posible extractor de features, definimos cual usar (similar a un Grid Search, pero a mano).\n",
    "Definimos también distintos clasificadores para utilizar.\n",
    "Finalmente evaluamos todas las posibles combinaciones realizando un 10-Fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_simple_features = [False, True]\n",
    "opt_vectorizers = [None, 'bow', 'tfidf', 'hashing_bow']\n",
    "opt_classifier = ['dt',\n",
    "                  'random_forest', \n",
    "                  'bernoulli_nb',\n",
    "                  'multinomial_nb',\n",
    "                  'knn',\n",
    "                  'svm']\n",
    "\n",
    "classifier_dict = {'dt': DecisionTreeClassifier,\n",
    "                  'random_forest': RandomForestClassifier, \n",
    "                  'bernoulli_nb': BernoulliNB,\n",
    "                  'multinomial_nb': MultinomialNB, \n",
    "                  'knn': KNeighborsClassifier, \n",
    "                  'svm': SVC}\n",
    "\n",
    "def build_models():\n",
    "    \"\"\"Construye todos los modelos para evaluar\"\"\"\n",
    "    \n",
    "    models = []\n",
    "    print 'Building models'\n",
    "    t0 = time.time()\n",
    "    for simple_features in opt_simple_features:\n",
    "        for subject_vect in opt_vectorizers:\n",
    "            for body_vect in opt_vectorizers:\n",
    "                extractor_tuple = splitted_features_extractors(simple_features, subject_vect, body_vect)\n",
    "                \n",
    "                if extractor_tuple is None:\n",
    "                    continue\n",
    "\n",
    "                extractors, features_name = extractor_tuple     \n",
    "\n",
    "                for classifier in opt_classifier: \n",
    "                    model = Pipeline([\n",
    "                      ('features_extractor', extractors),\n",
    "                      ('classifier', classifier_dict[classifier]())\n",
    "                    ])\n",
    "\n",
    "                    models = models + [(features_name, classifier, model)]\n",
    "                    \n",
    "    for simple_features in opt_simple_features:\n",
    "        for subject_and_body_vect in opt_vectorizers:\n",
    "            extractor_tuple = merged_features_extractors(simple_features, subject_and_body_vect)\n",
    "            \n",
    "            if extractor_tuple is None:\n",
    "                continue\n",
    "\n",
    "            extractors, features_name = extractor_tuple     \n",
    "\n",
    "            for classifier in opt_classifier: \n",
    "                model = Pipeline([\n",
    "                  ('features_extractor', extractors),\n",
    "                  ('classifier', classifier_dict[classifier]())\n",
    "                ])\n",
    "\n",
    "                models = models + [(features_name, classifier, model)]\n",
    "    \n",
    "    duration = time.time() - t0\n",
    "    print \"Done in %fs\" % duration\n",
    "    return models\n",
    "\n",
    "def score_models(models, train_set):\n",
    "    \"\"\"\n",
    "    Evalua con 10-Fold CV todos los modelos usando X e y como datos.\n",
    "    Guarda los puntajes y los tiempos de evaluacion en archivos Pickle\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = {}\n",
    "    times = {}\n",
    "    \n",
    "    X = train_set.drop('label', axis=1)\n",
    "    y = train_set['label']\n",
    "\n",
    "    for features_name, classifier_name, model in models:\n",
    "        print 'Running 10-Fold CV for model', features_name + '_' +  classifier_name                     \n",
    "                            \n",
    "        t0 = time.time()\n",
    "        score = cross_val_score(model, X, y, cv=10, n_jobs=8)\n",
    "        duration = time.time() - t0\n",
    "        print \"Done in %fs\" % duration\n",
    "        \n",
    "        if not features_name in scores:\n",
    "            scores[features_name] = {}\n",
    "            times[features_name] = {}\n",
    "            \n",
    "        scores[features_name][classifier_name] = score\n",
    "        times[features_name][classifier_name] = duration\n",
    "                            \n",
    "        print 'CV Scores: ', score\n",
    "        print 'Mean: ', np.mean(score), 'Std: ', np.std(score)\n",
    "        print ''\n",
    "    \n",
    "    # Las filas van a ser la elección de features y las columnas los clasificadores\n",
    "    scores = pd.DataFrame.from_dict(scores).transpose()\n",
    "    times = pd.DataFrame.from_dict(times).transpose()\n",
    "\n",
    "    joblib.dump(scores, 'features_experiments/features_cv_scores.pkl', compress=True)\n",
    "    joblib.dump(times, 'features_experiments/features_cv_times.pkl', compress=True)\n",
    "    \n",
    "    return scores, times\n",
    "\n",
    "def load_models():\n",
    "    \"\"\"Carga de archivos Pickle los puntajes y los tiempos calculados previamente\"\"\"\n",
    "    \n",
    "    scores = joblib.load('features_experiments/features_cv_scores.pkl')\n",
    "    times = joblib.load('features_experiments/features_cv_times.pkl')\n",
    "    \n",
    "    return scores, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summary(scores, times):\n",
    "    \"\"\"Imprime un resumen con distintas estadisticas sobre los datos\"\"\"\n",
    "    # Calculo en cada celda el promedio de los cross validation scores\n",
    "    scores_mean = scores.applymap(np.mean)\n",
    "    \n",
    "     # Estadistica: Promedio sobre todos los clasificadores para cada eleccion de features\n",
    "    mean = scores_mean.mean(axis=1)\n",
    "    print 'Max of Mean Score Across Classifiers: %f for Extractor \\'%s\\'' % (mean.max(), mean.idxmax())\n",
    "    \n",
    "    # Estadistica: UCB sobre todos los clasificadores para cada eleccion de features\n",
    "    # Inspirado por Optimización Bayesiana\n",
    "    ucb = scores_mean.mean(axis=1) + 0.5 * scores_mean.std(axis=1)\n",
    "    print 'Max of UCB Score Across Classifiers: %f for Extractor \\'%s\\'' % (ucb.max(), ucb.idxmax())\n",
    "    \n",
    "    # Estadistica: Mejor clasificador para cada eleccion de features\n",
    "    best_clf = scores_mean.max(axis=1)\n",
    "    best_clf_name = scores_mean.idxmax(axis=1)\n",
    "    print 'Max of Score Using Best Classifier: %f for Extractor \\'%s\\' and Classifier \\'%s\\'' % \\\n",
    "        (best_clf.max(), best_clf.idxmax(), best_clf_name[best_clf.idxmax()])\n",
    "        \n",
    "    # Estadistica: Promedio sobre todos los clasificadores para cada eleccion de features\n",
    "    mean = times.mean(axis=1)\n",
    "    print 'Min of Mean Time Across Classifiers: %f for Extractor \\'%s\\'' % (mean.min(), mean.idxmin())\n",
    "    \n",
    "    # Estadistica: Mejor clasificador para cada eleccion de features\n",
    "    fastest_clf = times.max(axis=1)\n",
    "    fastest_clf_name = times.idxmax(axis=1)\n",
    "    print 'Min of Time Using Fastest Classifier: %f for Extractor \\'%s\\' and Classifier \\'%s\\'' % \\\n",
    "        (fastest_clf.max(), fastest_clf.idxmax(), fastest_clf_name[fastest_clf.idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building models\n",
      "Done in 0.003000s\n",
      "Running 10-Fold CV for model body_bow_dt\n"
     ]
    }
   ],
   "source": [
    "scores, times = score_models(build_models(), train_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(scores, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
