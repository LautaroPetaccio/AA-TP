{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es decidir que extractores de features usamos en el pipeline principal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Development\\Anaconda2\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import features as cf\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decidimos definir los siguientes extractores de features:\n",
    "1. Features sencillos, definidos en features.py, como por ejemplo longitud del cuerpo del mail, o si contiene imagenes\n",
    "2. Vectorización (ya sea por medio del método Bag Of Words, del método TF-IDF, o del método Hashing Vectorizer) del Subject\n",
    "3. Vectorización (idem anterior) del Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitted_features_extractors_names(simple_features=True,\n",
    "                        subject_vectorizer='bow',\n",
    "                        body_vectorizer='bow'):\n",
    "    if simple_features:\n",
    "        features_name = 'simple_'\n",
    "    else:\n",
    "        features_name = ''\n",
    "        \n",
    "    if subject_vectorizer is not None:\n",
    "        features_name = features_name + 'subject_' + subject_vectorizer + '_'\n",
    "\n",
    "    if body_vectorizer is not None:\n",
    "        features_name = features_name + 'body_' + body_vectorizer + '_'\n",
    "        \n",
    "    features_name = features_name[:-1]\n",
    "\n",
    "    if features_name == '':\n",
    "        return None\n",
    "    \n",
    "    return features_name\n",
    "    \n",
    "def merged_features_extractors_names(simple_features=True, merged_vectorizer='bow'):\n",
    "    if simple_features:\n",
    "        features_name = 'simple_'\n",
    "    else:\n",
    "        features_name = ''\n",
    "        \n",
    "    if merged_vectorizer is not None:\n",
    "        features_name = features_name + 'subject_and_body_' + merged_vectorizer + '_'\n",
    "\n",
    "    features_name = features_name[:-1]\n",
    "\n",
    "    if features_name == '':\n",
    "        return None\n",
    "    \n",
    "    return features_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada posible extractor de features, definimos cual usar (similar a un Grid Search, pero a mano).\n",
    "Definimos también distintos clasificadores para utilizar.\n",
    "Finalmente evaluamos todas las posibles combinaciones realizando un 10-Fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_simple_features = [True, False]\n",
    "opt_vectorizers = [None, 'bow', 'tfidf', 'hashing_bow']\n",
    "opt_classifier = ['dt',\n",
    "                  'random_forest', \n",
    "                  'bernoulli_nb',\n",
    "                  'multinomial_nb',\n",
    "                  'knn',\n",
    "                  'svm']\n",
    "\n",
    "classifier_dict = {'dt': DecisionTreeClassifier,\n",
    "                  'random_forest': RandomForestClassifier, \n",
    "                  'bernoulli_nb': BernoulliNB,\n",
    "                  'multinomial_nb': MultinomialNB, \n",
    "                  'knn': KNeighborsClassifier, \n",
    "                  'svm': SVC}\n",
    "\n",
    "def get_models_names():    \n",
    "    models_names = []\n",
    "    for simple_features in opt_simple_features:\n",
    "        for subject_vect in opt_vectorizers:\n",
    "            for body_vect in opt_vectorizers:\n",
    "                features_name = splitted_features_extractors_names(simple_features, subject_vect, body_vect)\n",
    "                \n",
    "                if features_name is None:\n",
    "                    continue\n",
    "\n",
    "                for classifier in opt_classifier:\n",
    "                    models_names = models_names + [features_name + '_' + classifier]\n",
    "                    \n",
    "    for simple_features in opt_simple_features:\n",
    "        for subject_and_body_vect in opt_vectorizers:\n",
    "            features_name = merged_features_extractors_names(simple_features, subject_and_body_vect)\n",
    "            \n",
    "            if features_name is None:\n",
    "                continue\n",
    "\n",
    "            for classifier in opt_classifier: \n",
    "                models_names = models_names + [features_name + '_' + classifier]\n",
    "    \n",
    "    return models_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_names = get_models_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/228\n"
     ]
    }
   ],
   "source": [
    "print '%d/%d' % (models_names.index('simple_subject_hashing_bow_body_bow_random_forest'), len(models_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
