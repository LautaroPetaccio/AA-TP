{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Automatico - TP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "pd.options.display.float_format = '{:g}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import features as cf\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset, lo convertimos a un pandas DataFrame y separamos en set de entrenamiento y de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train Set\n",
      "Done in 0.931000s\n",
      "\n",
      "Loading Test Set\n",
      "Done in 0.224000s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Por reproducibilidad, y para no perder tiempo armando el DataFrame cada vez, lo bajamos a\n",
    "# un archivo la priemra vez que lo corrimos, ya seprando 20% para reportar como valor final\n",
    "# de nuestro modelo\n",
    "train_set_name = 'dataset/train_set.pkl'\n",
    "test_set_name = 'dataset/test_set.pkl'\n",
    "train_set = None\n",
    "test_set = None\n",
    "\n",
    "if os.path.isfile(train_set_name) and os.path.isfile(test_set_name):\n",
    "    print 'Loading Train Set'    \n",
    "    train_set = print_time(lambda: joblib.load(train_set_name))\n",
    "    print ''\n",
    "        \n",
    "    print 'Loading Test Set'\n",
    "    test_set = print_time(lambda: joblib.load(test_set_name))\n",
    "    print ''\n",
    "else:\n",
    "    train_set, test_set = load_raw_data()\n",
    "    print ''\n",
    "    \n",
    "    print 'Saving Train Set'\n",
    "    print_time(lambda: joblib.dump(train_set, train_set_name, compress=True))\n",
    "    print ''\n",
    "    \n",
    "    print 'Saving Test Set'\n",
    "    print_time(lambda: joblib.dump(test_set, test_set_name, compress=True))\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: 72000 samples - ham: 35997(0.50%) spam: 36003(0.50%)\n",
      "Test Set:  18000 samples - ham: 9003(0.50%) spam: 8997(0.50%)\n"
     ]
    }
   ],
   "source": [
    "print_sets_summarys(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionamos los primeros mails del set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_types</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[text/html]</td>\n",
       "      <td>penny st0ck booms on continued demand</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n\\r\\npenny st0ck booms on conti...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[text/plain]</td>\n",
       "      <td>RE: BNP Paribas Master Netting Agreement</td>\n",
       "      <td>The receivables deal has been terminated. Feel...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[text/plain]</td>\n",
       "      <td>I NEED YOU TO ACT AS THE NEXT OF KIN TO LATE M...</td>\n",
       "      <td>\\n\\n \\n \\nATTN:THE DIRECTOR /CEO,\\n\\nAN URGENT...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[text/plain]</td>\n",
       "      <td>WTI-Brent</td>\n",
       "      <td>Jeff -\\nDon't know if WTI-Brent is on the new ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[text/plain]</td>\n",
       "      <td>Mrs maureen clark</td>\n",
       "      <td>\\nDear Beloved in Christ,\\n\\nIt is by the grac...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  content_types                                            subject  \\\n",
       "0   [text/html]              penny st0ck booms on continued demand   \n",
       "1  [text/plain]           RE: BNP Paribas Master Netting Agreement   \n",
       "2  [text/plain]  I NEED YOU TO ACT AS THE NEXT OF KIN TO LATE M...   \n",
       "3  [text/plain]                                          WTI-Brent   \n",
       "4  [text/plain]                                  Mrs maureen clark   \n",
       "\n",
       "                                                body label  \n",
       "0  \\r\\n\\r\\n\\r\\n\\r\\n\\r\\npenny st0ck booms on conti...  spam  \n",
       "1  The receivables deal has been terminated. Feel...   ham  \n",
       "2  \\n\\n \\n \\nATTN:THE DIRECTOR /CEO,\\n\\nAN URGENT...  spam  \n",
       "3  Jeff -\\nDon't know if WTI-Brent is on the new ...   ham  \n",
       "4  \\nDear Beloved in Christ,\\n\\nIt is by the grac...  spam  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los siguientes atributos a ser extraidos de cada mail:\n",
    "\n",
    "1. Atributos simples:\n",
    "    - Longitud del asunto\n",
    "    - Cantidad de espacios en el asunto dividido por la longitud del asunto\n",
    "    - Cantidad de caracteres mayusculas en el asunto dividido por la longitud del asunto\n",
    "    - Longitud del cuerpo\n",
    "    - Cantidad de espacios en el cuerpo dividido por la longitud del cuerpo\n",
    "    - Cantidad de caracteres mayusculas en el cuerpo dividido por la longitud del cuerpo\n",
    "    - Cantidad de oraciones del cuerpo\n",
    "    - Tiene el mail contenido HTML?\n",
    "    - Tiene el mail im√°genes?\n",
    "    \n",
    "2. Atributos de vectorizacion del asunto: cantidad de apariciones por token dividido por la cantidad de documentos en los que aparece(TF-IDF)\n",
    "\n",
    "3. Atributos de vectorizacion del cuerpo: cantidad de apariciones por token dividido por la cantidad de documentos en los que aparece(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_extractors():\n",
    "    return cf.SimpleFeaturesExtractor([('subject_length', cf.subject_length), \n",
    "        ('subject_spaces', cf.subject_spaces), \n",
    "        ('subject_caps', cf.subject_caps),\n",
    "        ('body_length', cf.body_length), \n",
    "        ('body_spaces', cf.body_spaces), \n",
    "        ('body_caps', cf.body_caps), \n",
    "        ('body_sentences', cf.body_sentences),\n",
    "        ('has_html', cf.has_html), \n",
    "        ('has_image', cf.has_image)\n",
    "      ])\n",
    "def vectorizer_extractor():\n",
    "    return TfidfVectorizer(stop_words='english', \n",
    "                           ngram_range=(1, 2),\n",
    "                           strip_accents='ascii',\n",
    "                           sublinear_tf=True,\n",
    "                           min_df=0.001,\n",
    "                           max_df=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sobre los atributos de vectorizacion, damos la posiblidad de aplicar LSA, agregando PCA(tecnicamente, TruncatedSVD, pero a fines practicos es lo mismo) al pipeline correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def features_extractors(simple_features=True, subject_vectorizer=True, subject_lsa=True, body_vectorizer=True, body_lsa=True):\n",
    "    extractors = []\n",
    "    \n",
    "    if simple_features:\n",
    "        # Extractor de atributos simples\n",
    "        extractors = [('simple_features', simple_extractors())]\n",
    "    \n",
    "    if subject_vectorizer:\n",
    "        # Pipeline para extraer atributos de vectorizacion del asunto del mail\n",
    "        if subject_lsa:\n",
    "            extractors = extractors + \\\n",
    "                [('subject', Pipeline([\n",
    "                    ('selector', ColumnSelectorExtractor('subject')),\n",
    "                    ('vectorizer', vectorizer_extractor()),\n",
    "                    ('svd', TruncatedSVD(n_components=20))\n",
    "                ]))]\n",
    "        else:            \n",
    "            extractors = extractors + \\\n",
    "                [('subject', Pipeline([\n",
    "                    ('selector', ColumnSelectorExtractor('subject')),\n",
    "                    ('vectorizer', vectorizer_extractor())\n",
    "                ]))]\n",
    "            \n",
    "    if body_vectorizer:\n",
    "        # Pipeline para extraer atributos de vectorizacion del cuerpo del mail\n",
    "        if body_lsa:\n",
    "            extractors = extractors + \\\n",
    "                [('body', Pipeline([\n",
    "                    ('selector', ColumnSelectorExtractor('body')),\n",
    "                    ('vectorizer', vectorizer_extractor()),\n",
    "                    ('svd', TruncatedSVD(n_components=50))\n",
    "                ]))]\n",
    "        else:\n",
    "            extractors = extractors + \\\n",
    "                [('body', Pipeline([\n",
    "                    ('selector', ColumnSelectorExtractor('body')),\n",
    "                    ('vectorizer', vectorizer_extractor()),\n",
    "                ]))]\n",
    "    \n",
    "    # Use FeatureUnion to combine the features\n",
    "    return FeatureUnion(extractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n de modelos\n",
    "\n",
    "Probamos distintas configuracions de atributos y clasificadores, obteniendo para cada uno sus puntajes de 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    'tree_classifier__max_features': ['sqrt', 'log2', 0.5, None],\n",
    "    'tree_classifier__max_depth': [3, 5, 10, None],\n",
    "    'tree_classifier__min_samples_split': [1, 3, 5, 10],\n",
    "    'tree_classifier__min_samples_leaf': [1, 3, 5, 10]\n",
    "}\n",
    "\n",
    "dt = GridSearchCV(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False)),\n",
    "  ('tree_classifier', DecisionTreeClassifier())\n",
    "]), parameters_grid, n_jobs=4, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   48.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.93483333,  0.93383333,  0.92895833])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False)),\n",
    "  ('tree_classifier', DecisionTreeClassifier(max_features='sqrt', max_depth=None))\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   48.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.929     ,  0.92966667,  0.93204167])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False)),\n",
    "  ('tree_classifier', DecisionTreeClassifier(max_features='log2', max_depth=None))\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   49.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.93270833,  0.93745833,  0.936375  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False)),\n",
    "  ('tree_classifier', DecisionTreeClassifier(max_features=0.5, max_depth=None))\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   50.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.93608333,  0.93345833,  0.93379167])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False)),\n",
    "  ('tree_classifier', DecisionTreeClassifier(max_features=None, max_depth=None))\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   51.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.93825   ,  0.93570833,  0.93941667])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False)),\n",
    "  ('tree_classifier', DecisionTreeClassifier(max_features=None, max_depth=10))\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   51.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.96041667,  0.95933333,  0.9605    ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False, True, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   50.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.958125  ,  0.95791667,  0.95504167])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, False, False, True, True)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.98529167,  0.98491667,  0.984625  ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, False, False, True, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.98258333,  0.98241667,  0.98216667])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, False, False, True, True)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.98266667,  0.98304167,  0.98229167])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, True, True, True, True)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.98533333,  0.98570833,  0.98479167])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, True, False, True, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.97858333,  0.97908333,  0.97925   ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, True, True, True, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.981875  ,  0.98320833,  0.98091667])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, True, False, True, True)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, True, False, False, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(False, True, True, False, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, True, False, False, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:   50.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.94495833,  0.94866667,  0.9465    ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Pipeline([\n",
    "  ('features_extractor', features_extractors(True, True, True, False, False)),\n",
    "  ('tree_classifier', RandomForestClassifier())\n",
    "]), train_set, train_set['label'], n_jobs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
